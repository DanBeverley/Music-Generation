{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1246998,"sourceType":"datasetVersion","datasetId":716027}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport logging\nfrom pretty_midi import PrettyMIDI\n\nfrom pathlib import Path\nfrom typing import Callable, Any, Dict, List\n\nfrom torch.utils.data import Dataset\n\nlogger = logging.getLogger(__name__)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class AbstractMusicDataset(Dataset):\n    \"\"\"\n    Abstract base class for music dataset\n\n    Args:\n        data_path (List[Path]) : Path to the dataset\n        preprocess_fn (Callable): Function to preprocess a single sample\n        max_seq_len (int) : Maximum sequence length of the data\n        pad_token (int) : token used for padding sequences\n    \"\"\"\n    def __init__(self, data_path:List[Path],\n                preprocess_fn:Callable, max_seq_len:int,\n                pad_token:int):\n        self.data_path = data_path\n        self.preprocess_fn = preprocess_fn\n        self.max_seq_len = max_seq_len\n        self.pad_token = pad_token\n        self.data = self.load_data()\n    def load_data(self)->List[Any]:\n        \"\"\"Load any data from specified data path, Override this in subclasses\"\"\"\n        raise NotImplementedError(\"Subclasses must implement this method\")\n\n    def preprocess(self, sample:Any)->Dict[str,Any]:\n        \"\"\"Preprocess a single data sample\"\"\"\n        return self.preprocess_fn(sample, max_seq_len=self.max_seq_len,\n                                 pad_token=self.pad_token)\n    def __len__(self)->int:\n        return len(self.data)\n    def __getitem__(self, idx:int)->Dict[str,Any]:\n        return self.preprocess(self.data[idx])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def midi_preprocess(sample:PrettyMIDI, max_seq_len:int, pad_token:int,\n                   sos_token:int, eos_token:int\n                    , default_sample=None)->Dict[str, torch.Tensor]:\n    \"\"\"\n    Preprocess a MIDI sample: tokenize, truncate, and pad.\n\n    Args:\n        sample (MidiFile): MIDI file sample.\n        max_seq_len (int): Maximum sequence length.\n        pad_token (int): Padding token.\n    Returns:\n        Dict[str, torch.Tensor]: Preprocessed sample with input IDs and labels.\n    \"\"\"\n    try:\n        if not sample.instruments:\n            logger.warning(\"MIDI file has no instruments.\")\n            return default_sample or {\n                \"input_ids\":torch.full((max_seq_len), pad_token, dtype=torch.long)\n            }\n        tokens = []\n        for instrument in sample.instruments:\n            for note in instrument.notes:\n                tokens.append(note.pitch)\n        tokens = [sos_token] + tokens[:max_seq_len-2]+[eos_token]\n        padded_tokens = torch.nn.functional.pad(torch.tensor(tokens,\n                                                             dtype = torch.long),\n                                               (0, max_seq_len-len(tokens)),\n                                               value=pad_token)\n        logger.info(f\"Processed MIDI file : {len(tokens)} tokens\")\n        return {\"input_ids\":padded_tokens,\n               \"labels\":padded_tokens}\n    except Exception as e:\n        logger.error(f\"Error preprocessing MIDI: {e}\")\n        return default_sample or {\n            \"input_ids\":torch.full((max_seq_len), pad_token, dtype=torch.long),\n            \"labels\":torch.full(size(max_seq_len), pad_token, dtype=torch.long)}","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}