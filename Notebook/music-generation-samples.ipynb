{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1246998,"sourceType":"datasetVersion","datasetId":716027}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install miditoolkit\n!pip install torchtoolkit\n\n\nimport json\nimport torch\nimport logging\nimport pandas as pd\nfrom pretty_midi import PrettyMIDI\n\nfrom pathlib import Path\nfrom typing import Callable, Any, Dict, List\nfrom miditoolkit import MidiFile\nfrom miditok import REMI, TokenizerConfig\nfrom torchtoolkit.data import create_subsets\nfrom tqdm import tqdm\n\nfrom torch.utils.data import Dataset\nfrom torch import LongTensor\n\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class AbstractMusicDataset(Dataset):\n    \"\"\"\n    Abstract base class for music dataset\n\n    Args:\n        data_path (List[Path]) : Path to the dataset\n        preprocess_fn (Callable): Function to preprocess a single sample\n        max_seq_len (int) : Maximum sequence length of the data\n        pad_token (int) : token used for padding sequences\n    \"\"\"\n    def __init__(self, data_path:List[Path],\n                preprocess_fn:Callable, max_seq_len:int,\n                pad_token:int, **kwargs):\n        self.data_path = data_path\n        self.preprocess_fn = preprocess_fn\n        self.max_seq_len = max_seq_len\n        self.pad_token = pad_token\n        self.kwargs = kwargs\n        self.data = self.load_data(**kwargs)\n    def load_data(self, **kwargs)->List[Any]:\n        \"\"\"Load any data from specified data path, Override this in subclasses\"\"\"\n        raise NotImplementedError(\"Subclasses must implement this method\")\n\n    def preprocess(self, sample:Any)->Dict[str,Any]:\n        \"\"\"Preprocess a single data sample\"\"\"\n        return self.preprocess_fn(sample, max_seq_len=self.max_seq_len,\n                                 pad_token=self.pad_token)\n    def __len__(self)->int:\n        return len(self.data)\n    def __getitem__(self, idx:int)->Dict[str,Any]:\n        return self.preprocess(self.data[idx])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class MIDIDataset(AbstractMusicDataset):\n    def __init__(self, data_path:List[Path],preprocess_fn:Callable,\n                 max_seq_len:int, pad_token:int):\n        super().__init__(data_path, preprocess_fn,\n                         max_seq_len, pad_token)\n    def load_data(self)->List[MidiFile]:\n        \"\"\"Load MIDI file from dataset directory\"\"\"\n        try:\n            files = list(self.data_path.glob(\"*.midi\"))\n            if not files:\n                logger.warning(f\"No MIDI files found in: {self.data_path}\")\n                return []\n            return [MidiFile(str(file)) for file in files]\n        except FileNotFoundError:\n            logger.error(f\"MIDI directory not found: {self.data_path}\")\n            return []\n        except Exception as e:\n            logger.error(f\"Error loading MIDI files: {e}\")\n            return []","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class CSVDataset(AbstractMusicalDataset):\n    def __init__(self, data_path:List[Path],preprocess_fn:Callable,\n                 csv_filename:str, max_seq_len:int):\n        super().__init__(data_path, preprocess_fn, max_seq_len, pad_token,\n                        csv_filename = csv_filename)\n        self.csv_filename = csv_filename\n    def load_data(self, csv_filename:str)->List[Dict[str, Any]]:\n        \"\"\"Load the CSV file into a list of dictionaries\"\"\"\n        csv_path = self.data_path/self.csv_filename # Use Path object for joining\n        try:\n            df = pd.read_csv(str(csv_path)) \n            return df.to_dict(orient=\"records\")\n        except FileNotFoundError:\n            logger.error(f\"CSV file not found: {csv_path}\")\n            return []\n        except pd.errors.ParseError as e:\n            logger.error(f\"Error parsing CSV file: {e}\")\n            return []\n        except Exception as e:\n            logger.error(f\"An unexpected error occured while loading or parsing CSV file: {e}\")\n            return []","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class JSONDataset(AbstractMusicalDataset):\n    def __init__(self, data_path:List[Path], preprocess_fn:Callable,\n                max_seq_len:int, pad_token:int, json_filename:str):\n        super().__init__(data_path, preprocess_fn, max_seq_len, pad_token,\n                        json_filename = json_filename)\n        self.json_filename = json_filename\n    def load_data(self, json_filename:str)->List[Dict[str, Any]]:\n        \"\"\"Load a JSON file containing the dataset.\"\"\"\n        json_path = self.data_path[0]/self.json_filename\n        try:\n            with open(str(json_path), \"r\") as f:\n                return json.load(f)\n        except FileNotFoundError:\n            logger.error(f\"JSON file not found: {json_path}\")\n            return []\n        except json.JSONDecodeError as e:\n            logger.error(f\"Error decoding JSON: {e}\")\n            return []\n        except Exception as e:\n            logger.error(f\"An unexpected error occured while loading or parsing JSON file: {e}\")\n            return []","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def midi_preprocess(sample:PrettyMIDI, max_seq_len:int, pad_token:int,\n                   sos_token:int, eos_token:int\n                    , default_sample=None)->Dict[str, torch.Tensor]:\n    \"\"\"\n    Preprocess a MIDI sample: tokenize, truncate, and pad.\n\n    Args:\n        sample (MidiFile): MIDI file sample.\n        max_seq_len (int): Maximum sequence length.\n        pad_token (int): Padding token.\n    Returns:\n        Dict[str, torch.Tensor]: Preprocessed sample with input IDs and labels.\n    \"\"\"\n    try:\n        if not sample.instruments:\n            logger.warning(\"MIDI file has no instruments.\")\n            return default_sample or {\n                \"input_ids\":torch.full((max_seq_len), pad_token, dtype=torch.long)\n            }\n        tokens = []\n        for instrument in sample.instruments:\n            for note in instrument.notes:\n                tokens.append(note.pitch)\n        tokens = [sos_token] + tokens[:max_seq_len-2]+[eos_token]\n        padded_tokens = torch.nn.functional.pad(torch.tensor(tokens,\n                                                             dtype = torch.long),\n                                               (0, max_seq_len-len(tokens)),\n                                               value=pad_token)\n        logger.info(f\"Processed MIDI file : {len(tokens)} tokens\")\n        return {\"input_ids\":padded_tokens,\n               \"labels\":padded_tokens}\n    except Exception as e:\n        logger.error(f\"Error preprocessing MIDI: {e}\")\n        return default_sample or {\n            \"input_ids\":torch.full((max_seq_len), pad_token, dtype=torch.long),\n            \"labels\":torch.full(size(max_seq_len), pad_token, dtype=torch.long)}\n\ndef csv_preprocess(sample:Dict[str, Any],\n                  max_seq_len:int,\n                  pad_token:int,\n                  sos_token:int,\n                  eos_token:int,\n                  default_sample:Dict[str, torch.Tensor]=None)->Dict[str, torch.Tensor]:\n    \"\"\"\n    Preprocess CSV data for model input.\n\n    Args:\n        sample: A dictionary containing 'notes' as a key with a list of integer tokens.\n        max_seq_len: The maximum sequence length.\n        pad_token: The token used for padding.\n        sos_token: The start-of-sequence token.\n        eos_token: The end-of-sequence token.\n        default_sample: Optional default sample for invalid data.\n\n    Returns:\n        A dictionary with 'input_ids' and 'labels' tensors.\n    \"\"\"\n    try:\n        # For validating input format\n        if not isinstance(sample, dict) or \"notes\" not in sample:\n            raise ValueError(\"Invalid CSV sample format: missing 'notes' key.\")\n        tokens = sample[\"notes\"]\n        # Check token validity\n        if not all(isinstance(token, int) for token in tokens):\n            raise TypeError(\"CSV tokens must be integers.\")\n\n        # Add special tokens and truncats\n        tokens = [sos_token] + tokens[:max_seq_len-2]+[eos_token]\n        # Pad the sequence\n        padded_tokens = torch.nn.functional.pad(torch.tensor(tokens, dtype=torch.long),\n                                               (0, max_seq_len-len(tokens)),\n                                               value=pad_token)\n        logger.info(f\"Processed CSV data: {len(tokens)} tokens (max {max_seq_len}).\")\n        return {\n            \"input_ids\": padded_tokens,\n            \"labels\":padded_tokens\n        }\n    except (ValueError, TypeError) as e:\n        logger.error(f\"Error preprocessing CSV: {e}\")\n        return default_sample or {\n            \"input_ids\":torch.full((max_seq_len), pad_token, dtype=torch.long),\n            \"labels\":torch.full((max_seq_len), pad_token, dtype=torch.long)\n        }\n\ndef json_preprocess(sample:Dict[str, Any],\n                   max_seq_len:int,\n                   pad_token:int,\n                   sos_token:int,\n                   default_sample:Dict[str, torch.Tensor]=None)->Dict[str,torch.Tensor]:\n    \"\"\"\n    Preprocess JSON data for model input.\n\n    Args:\n        sample: A dictionary containing 'sequence' as a key with a list of integer tokens.\n        max_seq_len: The maximum sequence length.\n        pad_token: The token used for padding.\n        sos_token: The start-of-sequence token.\n        eos_token: The end-of-sequence token.\n        default_sample: Optional default sample for invalid data.\n\n    Returns:\n        A dictionary with 'input_ids' and 'labels' tensors.\n    \"\"\"\n    try:\n        # Validate input format\n        if not isinstance(sample, dict) or \"sequence\" not in sample:\n            raise ValueError(\"Invalid JSON sample format: missing 'sequence' key.\")\n        tokens = sample[\"sequence\"]\n        \n        # Check token validity\n        if not all(isinstance(token,int) for token in tokens):\n            raise TypeError(\"JSON tokens must be integers.\")\n        # Add special tokens and truncate\n        tokens = [sos_token]+tokens[:max_seq_len-2]+[eos_token]\n        # Pad the sequence\n        padded_tokens = torch.nn.functional.pad(torch.tensor(tokens, dtype=torch.long),\n                                               (0, max_seq_len-len(tokens)), value=pad_token)\n        logger.info(f\"Processed JSON data: {len(tokens)} tokens (max {max_seq_len}).\")\n        return {\"input_ids\":padded_tokens,\n               \"labels\":padded_tokens}\n    except (ValueError, TypeError) as e:\n        logger.error(f\"Error preprocessing JSON:{e}\")\n        return default_sample or {\"input_ids\":torch.full((max_seq_len),pad_token, dtype=torch.long),\n                                 \"labels\":torch.full((max_seq_len), pad_token, dtype=torch.long)}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **Preprocessing for the specific MaestroV2 Dataset**","metadata":{}},{"cell_type":"code","source":"class MaestroDataset(Dataset):\n    \"\"\"\n    A dataset for processing Maestro MIDI files.\n\n    Args:\n        file_paths (list): List of paths to MIDI or JSON files.\n        min_seq (int): Minimum sequence length.\n        max_seq (int): Maximum sequence length.\n        tokenizer_config (TokenizerConfig, optional): Configuration for the tokenizer (default: None)\n        pad_token (int): The token used for padding sequences.\n        preprocess (bool): Whether to preprocess and save tokenized files.\n        output_dir (Path): Directory to save preprocessed token files.\n\n    Attributes:\n        samples (list): List of tokenized sequences.\n    \"\"\"\n    def __init__(self, file_paths:List[Path],\n                min_seq:int,\n                max_seq:int,\n                pad_token:int,\n                tokenizer_config: TokenizerConfig=None,\n                preprocess:bool=True,\n                output_dir:Path=None):\n        self.samples = []\n        self.pad_token = pad_token\n        # Preprocessing if needed\n        if preprocess and output_dir is not None:\n            self._preprocessing_(file_paths, tokenizer_config, output_dir)\n            file_paths = List(output_dir.glob(\"*.json\"))\n        # Load preprocessed tokens\n        self.load_samples(file_paths, min_seq, max_seq)\n    def _preprocessing_(self, file_paths:List[Path],\n                       tokenizer_config:TokenizerConfig,\n                       output_dir:Path):\n        output_dir.mkdir(parents=True, exist_ok=True)\n        for i in tqdm(file_paths, desc=\"Preprocessing MIDI files\"):\n            try:\n                if i.suffix in [\"MIDI\", \"MID\", \"midi\", \"mid\"]:\n                    midi = MidiFile(i)\n                    tokenizer = REMI(tokenizer_config) if tokenizer_config is not None else REMI()\n                    all_tracks_tokens = [tokenizer.midi_to_tokens(midi)[0].ids \n                                         for track in midi.tracks if len(track)>0]\n                    tokens = [token for track in all_tracks_tokens for token in track]\n                else:\n                    continue # Skip non-MIDI files\n                # Save tokens to JSON\n                output_file = output_dir/f\"{i.stem}_tokens.json\"\n                with open(output_file, \"w\") as f:\n                    json.dump({\"ids\":tokens}, f)\n            except Exception as e:\n                logger.warning(f\"Error processing {i}: {e}\")\n    def load_samples(self, file_paths:List[Path],\n                        min_seq:int,\n                        max_seq:int):\n        \"\"\"Load tokenized samples and create sequences\"\"\"\n        for file_path in tqdm(file_paths, desc=\"Loading tokenized files\"):\n            try:\n                with open(file_path, \"r\") as f:\n                    tokens = json.load(f)[\"ids\"]\n                # Create fixed length sequences\n                i = 0\n                while i<len(tokens):\n                    if i>=len(tokens)-min_seq:\n                        break\n                    self.samples.append(LongTensor(tokens[i:i+max_seq]))\n                    i+=len(self.samples[-1])\n            except Exception as e:\n                logger.warning(f\"Error loading {file_path}: {e}\")\n    def __getitem__(self, idx)->Dict[str, LongTensor]:\n        return {\"input_ids\":self.samples[idx],\n               \"labels\":self.samples[idx]}\n    def __len__(self)->int:\n        return len(self.samples)\n    def __regr__(self):\n        return self.__str__()\n    def __str__(self)->str:\n        return \"No data loaded\" if len(self)==0 else f\"{len(self.samples)} samples\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}